<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://h2o-ac.pages.dev/feed.xml" rel="self" type="application/atom+xml" /><link href="https://h2o-ac.pages.dev/" rel="alternate" type="text/html" /><updated>2022-09-11T18:01:04+00:00</updated><id>https://h2o-ac.pages.dev/feed.xml</id><title type="html">Gary Ding</title><subtitle>A personal technical blog for some interesting things in the learning process</subtitle><author><name>gary ding</name></author><entry><title type="html">Google Summer Of Code 2022 Report</title><link href="https://h2o-ac.pages.dev/tech/gsoc-2022-report.html" rel="alternate" type="text/html" title="Google Summer Of Code 2022 Report" /><published>2022-09-10T00:00:00+00:00</published><updated>2022-09-10T00:00:00+00:00</updated><id>https://h2o-ac.pages.dev/tech/gsoc-2022-report</id><content type="html" xml:base="https://h2o-ac.pages.dev/tech/gsoc-2022-report.html"><![CDATA[<h2 id="overview">Overview</h2>
<p>Over the past three months, I have had the valuable opportunity of contributing to an OpenCV open source project as a part of GSoC 2022. The main goal of this project was to create a cost-effective vision system for teams competing in the FIRST Robotics Competition by using the OpenCV DepthAI/OAK-D platform. Through this project, OAK-D can begin to be part of a solution to reduce build time by providing a generic and proven vision solution for all types of robots.</p>

<h2 id="goals">Goals</h2>
<ul>
  <li>Task 1: Create a new abstraction layer in FRC for person tracking and distance.</li>
  <li>Task 2: Create a new abstraction layer in FRC for object tracking and distance.</li>
  <li>Task 3: Create a new abstraction layer for AprilTag and ArUco tag homography.</li>
  <li>Task 4: Provide a way to simplify the calibration process/auto calibration.</li>
  <li>Task 5: Create a new abstraction layer for object identification.</li>
  <li>Task 6: Create a new process to have the training environment easily usable and consumable models from community.</li>
  <li>Task 7: Create documentation and tutorial on using this FRC software package.</li>
  <li>Task 8: Create documentation and tutorial on tuning a model and uploading to OAK-D.</li>
</ul>

<p>During the working period, I started by mainly focusing my assigned work on person tracking and distance. When I had met this goal, I worked with my mentors and moved onto completing the other goals that built off of this initial step, such as simplifying the training environment and documenting the setup instructions. This way, the full start-to-end toolkit that I had created with the person detector could be applied to the other abstraction layers as well.
Project Description #</p>

<h2 id="development-environment">Development Environment</h2>

<h3 id="oak-d-depthai">Oak-D DepthAI</h3>

<p>DepthAI is the Embedded, Performant, Spatial AI+CV platform, composed of an open-source hardware, firmware, software ecosystem that provides turnkey embedded Spatial AI+CV and hardware-accelerated computer vision. OAK was developed, which is a modular, open-source ecosystem composed of MIT-licensed hardware, software, and AI training. Oak-D is the stereo camera which runs the DepthAI. FRC lacks advanced vision-based solutions including the open source software and hardware that can be quickly adopted by developers.  The proposal is to create a package for the OAK-D camera for FRC.  Beyond that, the package can be used by any mobile robot to quickly implement vision based tasks</p>

<h3 id="javacpp-presets">JavaCpp-Presets</h3>

<p>The JavaCPP Presets modules contain Java configuration and interface classes for widely used C/C++ libraries. It provides efficient access to native C++ inside Java, not unlike the way some C/C++ compilers interact with assembly language. Since the DepthAI that was used for this project was created with C++ language, in order to create a Java version, we need to use a Java CPP glue layer which is what Java-Cpp is about.</p>

<h3 id="frc-roborio-simulation">FRC RoboRio Simulation</h3>

<p>RoboRio Simulation is a desktop tool designed to help developers  test FRC robot code. The simulator allows developers to test their robot code without the need for a physical robot or the RoboRIO component.  It fully supports the FRC WPILibrary in Java.</p>

<h3 id="streamlit">Streamlit</h3>
<p>Streamlit is an open source app framework in the Python language. It helps us create web apps for data science and machine learning in a short time. For this project, we used Streamlit to create a web-based user interface for teams to adjust parameters for the vision pipeline.</p>

<h2 id="implementation">Implementation</h2>

<h3 id="the-python-implementation-with-test-gui">The Python Implementation with test GUI</h3>
<p>The DepthAI platform has low level functions for object detection and depth calculation but these examples are separate programs. Developers will need to understand the details and gist of how object and depth detection works in order to put them together. In the first phase of the working period, I spent time familiarizing myself with the depths of this code. Afterwards, I created two separate programs for detection based off of input, which was either a live feed from the OAK-D camera or a video from a file. In my initial iterations, I created an asynchronous detection process with the use of a long running thread. This worked in some cases but not all. Based on mentor feedback, I created a synchronous call instead so that once a person is detected, then at that point a result will be returned. The result of the pipeline includes values such as a boolean statement, bounding box coordinates, and depth. 
Once the initial detection networks were functioning, I created a web-based UI through streamlit to simplify the process of fine-tuning parameters to alter the result. With a web-based UI, developers can tune the pipeline regardless of their operating system. I added functionalities that included specifying the pipeline input, model file, confidence threshold, and a live display. 
Finally, I made it possible to return the results from the python code to the robot using the FRC WPILibrary NetworkTables function, which is a distributed message bus so that other software components can read the results, even if these components are in different processors.</p>

<p>Refer to  <a href="https://23garyd.github.io/gsoc-python-linux.html">this link</a> for setup instructions.</p>

<h3 id="the-java-implementation-with-roborio-simulator">The Java Implementation with RoboRio Simulator</h3>
<p>Due to the large number of FRC teams that have Java as their preferred programming language, I felt that it was necessary to add Java support for this project as I was finishing up my Python code. However, the Java implementation was quite an involved process.  Since DepthAI does not have a Java library, this work would have had to be done based on low-level code from the C++ library. Thankfully, there is an open-source project, JavaCPP-Presets, which provides some form of a JNI-layer wrapper for some common C++ components. I modified the JavaCPP to create a depthAI jar wrapper and then ported my person detection Python code to Java. Through unit testing, I made sure that this process was successful. 
Then, I utilized NetworkTables from the FRC WPILibrary in order to use the outputs from the pipeline as input to the RoboRIO processor found on FRC robots, so that teams can use the results for positioning or other judgements. Since I didnâ€™t have access to the RoboRIO hardware, I chose to install and use a FRC RoboRIO simulator which can mimic the NetworkTables function. With the setup complete, I tested the Java code with a OAK-D and this simulator and it worked as expected.</p>

<p>Refer to  <a href="https://23garyd.github.io/gsoc-java-linux.html">this link</a> for setup instructions.</p>

<h2 id="commits">Commits</h2>
<ul>
  <li>python-ironoak  <a href="https://github.com/23garyd/python-ironoak">python-ironoak </a>
    <ul>
      <li>https://github.com/prasannavk/python-ironoak/pull/4/commits</li>
      <li></li>
    </ul>
  </li>
  <li>java-ironoak <a href="https://github.com/23garyd/java-ironoak">java-ironoak </a>
    <ul>
      <li>https://github.com/23garyd/java-ironoak/commits/main</li>
    </ul>
  </li>
</ul>

<h2 id="video-links">Video Links</h2>

<p>Python FRC demo</p>
<iframe type="text/html" width="100%" height="385" src="https://www.youtube.com/embed/kZoewUklqjo" frameborder="0"></iframe>

<p>Java FRC demo</p>
<iframe type="text/html" width="100%" height="385" src="https://www.youtube.com/embed/Er9NpnCAC9k" frameborder="0"></iframe>]]></content><author><name>gary ding</name></author><category term="tech" /><category term="Java" /><category term="Python" /><category term="FRC" /><category term="Linux" /><summary type="html"><![CDATA[Overview Over the past three months, I have had the valuable opportunity of contributing to an OpenCV open source project as a part of GSoC 2022. The main goal of this project was to create a cost-effective vision system for teams competing in the FIRST Robotics Competition by using the OpenCV DepthAI/OAK-D platform. Through this project, OAK-D can begin to be part of a solution to reduce build time by providing a generic and proven vision solution for all types of robots.]]></summary></entry><entry><title type="html">Google Summer Of Code 2022 Java Setup</title><link href="https://h2o-ac.pages.dev/gsoc-java-linux.html" rel="alternate" type="text/html" title="Google Summer Of Code 2022 Java Setup" /><published>2022-09-10T00:00:00+00:00</published><updated>2022-09-10T00:00:00+00:00</updated><id>https://h2o-ac.pages.dev/gsoc-java-linux</id><content type="html" xml:base="https://h2o-ac.pages.dev/gsoc-java-linux.html"><![CDATA[<blockquote>
  <p>Google Summer Of Code Java version setup.</p>
</blockquote>

<h3 id="background">Background</h3>

<p>The object detection Java library is based on a OpenCV DepthAI C++ library. It can run on Linux, Windows and OSX platforms. The hardware supports X86_64 and ARM based embedded devices. I used the FRC WPILibrary simulator to test the results of the person detector so that the RoboRIO hardware is not necessary. The detection results will be passed to the simulator or actual RoboRIO by using the FRC WPILibrary NetworkTables components.</p>

<p><img src="/assets/img/frc-robo.png" alt="" /></p>

<h3 id="environment">Environment</h3>

<ul>
  <li>FRC RoboRIO simulator</li>
  <li>Ubuntu 20.04 on X86_64</li>
  <li>Oracle Java 8 SDK</li>
  <li>Maven 3.6.3</li>
  <li>DepthAPI driver</li>
  <li>OAK-D camera with USB connected to PC</li>
</ul>

<h3 id="linux-installation">Linux Installation</h3>

<p>There are some required dependencies that are needed to be compiled and installed in order to simulate the results on a RoboRIO.</p>

<ul>
  <li>RoboRIO Simulator: Refer to  <a href="https://docs.wpilib.org/en/stable/docs/software/wpilib-tools/robot-simulation/introduction.html">this link</a> for setup instructions. After a successful installation, the simulator should resemble the following:</li>
</ul>

<p><img src="/assets/img/frc-sim.png" alt="" /></p>

<ul>
  <li>JavaCpp for DepthAI: Refer to  <a href="https://github.com/bytedeco/javacpp-presets">this link</a> for build steps.
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  cd javacpp-presets
  mvn install --projects .,depthai
  cd javacpp-presets/depthAI/platform
  mvn clean install -Djavacpp.platform.host
</code></pre></div>    </div>
    <p>After the above steps are complete, a depthai-platform.jar will be created and installed in the maven repository.</p>
  </li>
  <li>WPILibrary NetworkTable component
    <ul>
      <li>
        <p>Since the version that I used has been removed from the maven repository, manual installation is necessary.  To begin, download the NetworkTables library from <a href="https://first.wpi.edu/FRC/roborio/maven/development/edu/wpi/first/wpilib/networktables/java/NetworkTables/3.1.7-20170802171912-5-gf43675e/NetworkTables-3.1.7-20170802171912-5-gf43675e-desktop.jar">this link</a>.</p>
      </li>
      <li>
        <p>Start a terminal and cd to the path where the jar file was saved. Once complete, run the below command to install this jar to the maven repository.</p>
      </li>
    </ul>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  mvn install:install-file -Dfile=./NetworkTables-3.1.7-20170802171912-5-gf43675e-desktop.jar  -DgroupId=edu.wpi.first.wpilib.networktables.java -DartifactId=NetworkTables -Dversion=3.1.7 -Dpackaging=jar

</code></pre></div>    </div>
  </li>
  <li>
    <p>java-ironoak install and run</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  git clone https://github.com/23garyd/java-ironoak.git
  mvn clean install
  mvn compile exec:java

</code></pre></div>    </div>
    <p>Make sure that the Oak-D is connected with the USB 3 port using the original cable. 
From the RoboRIO simulator, the person detectorâ€™s results have been passed  to the NetworkTables window, and should display the values for when a person has been detected.</p>
  </li>
</ul>

<p><img src="/assets/img/nt3.png" alt="" /></p>]]></content><author><name>gary ding</name></author><category term="Java" /><category term="Python" /><category term="FRC" /><category term="Linux" /><summary type="html"><![CDATA[Google Summer Of Code Java version setup.]]></summary></entry><entry><title type="html">Google Summer Of Code 2022 Python Setup</title><link href="https://h2o-ac.pages.dev/gsoc-python-linux.html" rel="alternate" type="text/html" title="Google Summer Of Code 2022 Python Setup" /><published>2022-09-10T00:00:00+00:00</published><updated>2022-09-10T00:00:00+00:00</updated><id>https://h2o-ac.pages.dev/gsoc-python-linux</id><content type="html" xml:base="https://h2o-ac.pages.dev/gsoc-python-linux.html"><![CDATA[<blockquote>
  <p>Google Summer Of Code Python version setup.</p>
</blockquote>

<h3 id="background">Background</h3>

<p>The object detection Python library is based on a OpenCV DepthAI python library. It can run on Linux, Windows and OSX platforms. The hardware supports X86_64 and ARM based embedded devices. I used the FRC WPILibrary simulator to test the results of the person detector so that the RoboRIO hardware is not necessary. The detection results will be passed to the simulator or actual RoboRIO by using the FRC WPILibrary NetworkTables components. In addition, I also used Streamlit to create a web-based user interface to adjust various parameters and inputs for the person detector.</p>

<h3 id="environment">Environment</h3>

<ul>
  <li>FRC RoboRIO simulator</li>
  <li>Streamlit</li>
  <li>Ubuntu 20.04 on X86_64</li>
  <li>Python 3.6+</li>
  <li>DepthAPI driver</li>
  <li>OAK-D camera with USB connected to PC</li>
</ul>

<h3 id="linux-installation">Linux Installation</h3>

<p>There are some required dependencies that are needed to be compiled and installed in order to simulate the results on a RoboRIO.</p>

<ul>
  <li>
    <p>RoboRio Simulator: Refer <a href="https://docs.wpilib.org/en/stable/docs/software/wpilib-tools/robot-simulation/introduction.html">this link</a> for setup instructions. After a successful installation, the desktop should show a simulator like this.</p>
  </li>
  <li>
    <p>Streamlit: Refer this link](https://docs.streamlit.io/library/get-started/installation) for installation.</p>
  </li>
</ul>

<p><img src="/assets/img/frc-sim.png" alt="" /></p>

<ul>
  <li>DepthAI for Ubuntu, Refer to <a href="https://docs.luxonis.com/projects/api/en/latest/install/#ubuntu">this link</a>) for installation.
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  git clone https://github.com/luxonis/depthai-python.git
  cd depthai-python/examples
  python3 install_requirements.py
     
</code></pre></div>    </div>
    <p>Before starting the program with streamlit, it is important to check to make sure that driver has been installed correctly.</p>
  </li>
  <li>
    <p>Python-ironoak install and run</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  git clone https://github.com/23garyd/python-ironoak.git
  streamlit persondetector_ui_combo.py

</code></pre></div>    </div>
    <p>Make sure the OAK-D is connected with the USB 3 port with the original cable. After starting the program with streamlit, the detection results should appear on the RoboRIO simulator in real time.</p>
  </li>
</ul>

<p><img src="/assets/img/streamlit1.png" alt="" /></p>

<p>From the RoboRIO simulator, the detection results appear at the bottom of the NetworkTables window, in the row SmartDashboard. The values will update as the position of the detected person moves.</p>

<p><img src="/assets/img/nt3.png" alt="" /></p>]]></content><author><name>gary ding</name></author><category term="Java" /><category term="Python" /><category term="FRC" /><category term="Linux" /><summary type="html"><![CDATA[Google Summer Of Code Python version setup.]]></summary></entry></feed>