---
layout: post
title: 'LeRobot'
subtitle: 'Hugging Face library for real-world robotics'
date: 2024-06-15
categories: tech
author: Gary Ding
cover: '/assets/img/gary-lerobot1.jpg'
cover_author: ''
cover_author_link: ''
tags: 
- Python 
- Linux
pin: true
---

## Project Overview 

I served as a research intern, delving into robot automation for the pick and place operations of recycled phones within a warehouse setting. Hugging Face's LeRobot project represents an open - source initiative centered around machine - learning models tailored for real - world robotics applications. Notably, it operates within the realms of imitation and reinforcement learning. This project functions as a wrapper for the Stanford paper ALOHA. Stanford's ALOHA encompasses a suite of robotics systems. Its core objective is to develop affordable, open - source hardware dedicated to robotics research. Initially, ALOHA began as a bimanual teleoperation system. However, it has since progressed into Mobile ALOHA, a system that seamlessly integrates mobility with advanced whole - body manipulation capabilities. Mobile ALOHA is engineered to execute intricate real - world tasks such as cooking, cleaning, and navigating diverse environments. As a result, it has proven invaluable for research in fields like imitation learning and human - robot interaction.
The key deliverable of this project is the successful implementation of object pick - and - place functionality. 



## Implementation
![](/assets/img/gary-lerobot1.jpg)

![](/assets/img/gary-lerobot3.jpg)


# LeRobot Test Process  

## **Setup**  
- **Hardware:**  
  - **Data Collection & Inference:** Linux laptop with NVIDIA RTX 4070 GPU.  
  - **Robot Arms:** Custom-built based on [KOCH 1.1](https://github.com/koch-robotics/koch-1.1).  

## **Methodology**  
1. **Data Collection:**  
   - Performed **100 rounds** of task demonstrations.
   - Sensor data: RGB, joint states, and action trajectories recorded.  
```
   conda activate lerobot
   python lerobot/scripts/control_robot.py record_dataset --fps 30 --root data     --repo-id bobding/koch_test --num-episodes 100 --run-compute-stats 1     --warmup-time-s 2 --episode-time-s 200 --reset-time-s 10

...
(3190.6hz) dtRfoll: 6.07 (164.6hz) dtRlaptop:31.72 (31.5hz) dtRphone:35.48 (28.2hz)
INFO 2024-09-05 21:59:42 ol_robot.py:225 dt:33.34 (30.0hz) dtRlead: 0.60 (1666.3hz) dtWfoll: 0.27 (3648.0hz) dtRfoll: 6.05 (165.2hz) dtRlaptop:47.94 (20.9hz) dtRphone:35.48 (28.2hz)
INFO 2024-09-05 21:59:42 ol_robot.py:225 dt:33.33 (30.0hz) dtRlead: 0.81 (1230.6hz) dtWfoll: 0.28 (3575.7hz) dtRfoll: 5.94 (168.4hz) dtRlaptop:19.15 (52.2hz) dtRphone:50.18 (19.9hz)
INFO 2024-09-05 21:59:42 ol_robot.py:225 dt:33.33 (30.0hz) dtRlead: 0.62 (1615.1hz) dtWfoll: 0.32 (3151.7hz) dtRfoll: 6.03 (165.8hz) dtRlaptop:32.86 (30.4hz) dtRphone:47.11 (21.2hz)
INFO 2024-09-05 21:59:42 ol_robot.py:225 dt:33.33 (30.0hz) dtRlead: 0.76 (1322.5hz) dtWfoll: 0.29 
...

```

2. **Training:**  
   - Trained using ACT model. 
   - Training Parameters
   
| Hyperparameter       | Behavioral Cloning (BC) | Reinforcement Learning (RL) | Notes                         |
|----------------------|------------------------|----------------------------|-------------------------------|
| **Batch Size**       | `64-256`               | `256-512`                  | Larger batches for RL stability |
| **Learning Rate**    | `3e-4` (Adam)         | `1e-3` to `1e-4`           | Lower for fine-tuning         |
| **Training Epochs**  | `50-200`              | `500-1k+`                 | RL requires more iterations   |
| **Gamma (γ)**       | -                     | `0.99`                     | RL discount factor           |
| **τ (Polyak)**      | -                     | `0.005`                    | Target network update rate   |

```
DATA_DIR=data python lerobot/scripts/train.py policy=act_koch_real env=koch_real dataset_repo_id=bobding/koch_test  hydra.run.dir=outputs/train/act_koch_real

```
3. **Inference:**  
   - Deployed the trained policy on the same hardware for real-world testing.  

## **Results**  
- **Success Rate:** Achieved 80% on pick and place objects  
- **Key Observations:**  
  - Action is smoother if using two cameras.  
  - Material-specific failures (soft/transparent objects).   

## **Challenges & Improvements**  
- **Limitations:**  
  - Data diversity bottleneck  
- **Future Work:**  
  - Expand dataset with adversarial examples.  

---



<iframe width="100%" height="385" src="https://www.youtube.com/embed/9d4spT3aNjg" frameborder="0" allowfullscreen></iframe>






















